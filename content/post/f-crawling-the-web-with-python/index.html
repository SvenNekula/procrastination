---
title: '[F] Crawling the web with Python'
author: 'Sven '
date: '2021-04-08'
slug: []
categories:
  - Python
tags:
  - webcrawler
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>Hello again! Unfortunately I caught the corona virus a few weeks back and thus
had to stay in quarantine for ~2 weeks. Quarantine sucks, but at least I used
the time to get my python skills back up to par.</p>
<div id="the-project" class="section level1">
<h1>The project</h1>
<p>I wanted to create a webcrawler using python. Being a fun project, I used a website with data from all the pokemon to crawl the data and write it to a csv file.
During the process I found two ways to do so.
The first way required more code than the second one. But I will show you both.</p>
</div>
<div id="v1" class="section level1">
<h1>V1</h1>
<p>As usual we have to load the modules first.</p>
<pre class="python"><code>import requests
from bs4 import BeautifulSoup</code></pre>
<p>Next up we have to set the url and use the request package to make a http request.</p>
<pre class="python"><code>url = &#39;https://pokemondb.net/pokedex/all&#39;
r = requests.get(url)</code></pre>
<p>You can check if the request was successfull by printing the status code using
the command print(r.status_code). If the status-code is 200 you’re good. After
creating the request and checking if it was successfull we have to use the
‘BeautifulSoup’ module to parse the website’s html file.</p>
<pre class="python"><code>soup = BeautifulSoup(r.text, &#39;html.parser&#39;)</code></pre>
<p>After parsing the html file we can start to look for the data. In our case the
data is in a html-table, which we can find using the .find command.</p>
<pre class="python"><code>pokemon_table = soup.find(&#39;table&#39;, class_ = &#39;data-table block-wide&#39;)</code></pre>
<p>Now that we found the html-table we can make a list using a for loop. The
columns of the table have different classes however, which we can find by
inspecting the website using our web-browser. There were 3 different classes:
‘cell-name’, ‘cell-total’ and ‘cell-num’. There were 7 different elements of the
‘cell-num’-class, so we had to further inspect those elements, to get the right ones.
Having done that, we can create the list.</p>
<pre class="python"><code>pokemon_list = []
for pkmn in pokemon_table.find_all(&#39;tbody&#39;):
    rows = pkmn.find_all(&#39;tr&#39;)
    for row in rows:
        p_name = row.find(&#39;td&#39;, class_ = &#39;cell-name&#39;).text
        p_total = row.find(&#39;td&#39;, class_ = &#39;cell-total&#39;).text
        p_hp = row.find_all(&#39;td&#39;, class_ = &#39;cell-num&#39;)[1].text
        p_att = row.find_all(&#39;td&#39;, class_ = &#39;cell-num&#39;)[2].text
        p_def = row.find_all(&#39;td&#39;, class_ = &#39;cell-num&#39;)[3].text
        p_spatk = row.find_all(&#39;td&#39;, class_ = &#39;cell-num&#39;)[4].text
        p_spdef = row.find_all(&#39;td&#39;, class_ = &#39;cell-num&#39;)[5].text
        p_speed = row.find_all(&#39;td&#39;, class_ = &#39;cell-num&#39;)[6].text
        pokemon_list.append([p_name, p_total, p_hp, p_att, p_def, p_spatk, p_spdef, p_speed])</code></pre>
<p>The last step is to convert this list into a csv-file. We can do this with the help
of the csv module.</p>
<pre class="python"><code>import csv
with open(&#39;allpokemon.csv&#39;, &#39;w&#39;, newline=&#39;&#39;) as csvfile:
    pkmnwriter = csv.writer(csvfile, delimiter=&#39;;&#39;,
                            quotechar=&#39;&quot;&quot;&#39;, quoting=csv.QUOTE_MINIMAL)
    
    for row in pokemon_list:
        pkmnwriter.writerow</code></pre>
<p>Now we successfully transformed the website’s data into a csv-file!</p>
</div>
<div id="v2" class="section level1">
<h1>V2</h1>
<p>The second way of transforming the website’s data into a csv is a lot easier.
It only requires 4 lines of code, because we’re using pandas’ read_html function.
This function automatically scans the website for html-tables and converts them to
a list. One thing to keep in mind is to use the requests module the same way we used
it in V1, otherwise you might encounter some errors!</p>
<pre class="python"><code>import pandas as pd

pkmn_list = pd.read_html(r.text)
df = pd.DataFrame(pkmn_list[0])

df.to_csv (r&#39;P:\\GitHub\\webcrawler\\pokemon_list.csv&#39;, index = False, header=True)</code></pre>
<p>Those were 2 ways to crawl data from a website. Now we can further use the data
and analyze it.</p>
</div>
<div id="analyzing-the-data" class="section level1">
<h1>Analyzing the data</h1>
<p>Before analyzing the data I opened the csv file in excel and transformed it to
a .xslx file, because it makes it easier to work with (in excel).
To load the .xslx file into RStudio I used the ‘readxl’ package. I also used
‘dplyr’ and ‘ggplot2’ from the tidyverse package to filter and visualize the data.</p>
<p>Now we can get an overview of the data.</p>
<pre class="r"><code>#overview of data
str(pData)</code></pre>
<pre><code>## tibble[,10] [1,045 x 10] (S3: tbl_df/tbl/data.frame)
##  $ #      : num [1:1045] 1 2 3 3 4 5 6 6 6 7 ...
##  $ Name   : chr [1:1045] &quot;Bulbasaur&quot; &quot;Ivysaur&quot; &quot;Venusaur&quot; &quot;Venusaur Mega Venusaur&quot; ...
##  $ Type   : chr [1:1045] &quot;Grass Poison&quot; &quot;Grass Poison&quot; &quot;Grass Poison&quot; &quot;Grass Poison&quot; ...
##  $ Total  : num [1:1045] 318 405 525 625 309 405 534 634 634 314 ...
##  $ HP     : num [1:1045] 45 60 80 80 39 58 78 78 78 44 ...
##  $ Attack : num [1:1045] 49 62 82 100 52 64 84 130 104 48 ...
##  $ Defense: num [1:1045] 49 63 83 123 43 58 78 111 78 65 ...
##  $ Sp. Atk: num [1:1045] 65 80 100 122 60 80 109 130 159 50 ...
##  $ Sp. Def: num [1:1045] 65 80 100 120 50 65 85 85 115 64 ...
##  $ Speed  : num [1:1045] 45 60 80 80 65 80 100 100 100 43 ...</code></pre>
<p>If you have knowledge of Pokemon, you probably know that Eternamax is the strongest
Pokemon. However it’s just used in an NPC fight and can’t be used by the player,
which is why it has to be removed from the dataset, because it’s an extreme outlier.
This can be done multiple ways, I just chose to use the subset function, as I’ve
never used it.</p>
<pre class="r"><code>#removing Eternamax
pD &lt;- pData %&gt;% filter(Total&lt;1125)</code></pre>
<p>After finalizing the dataframe I wanted to work with, I wanted to get a more
detailled overview of the distributions of the stats. I used the summary command
for all the stat columns to see the min, max, median and mean of my data.</p>
<pre class="r"><code>pD %&gt;% select(4:10) %&gt;% summary()</code></pre>
<pre><code>##      Total             HP             Attack          Defense      
##  Min.   :175.0   Min.   :  1.00   Min.   :  5.00   Min.   :  5.00  
##  1st Qu.:330.0   1st Qu.: 50.00   1st Qu.: 55.00   1st Qu.: 50.00  
##  Median :458.0   Median : 68.00   Median : 77.00   Median : 70.00  
##  Mean   :438.7   Mean   : 69.89   Mean   : 80.43   Mean   : 74.49  
##  3rd Qu.:515.0   3rd Qu.: 82.00   3rd Qu.:100.00   3rd Qu.: 90.00  
##  Max.   :780.0   Max.   :255.00   Max.   :190.00   Max.   :230.00  
##     Sp. Atk          Sp. Def           Speed       
##  Min.   : 10.00   Min.   : 20.00   Min.   :  5.00  
##  1st Qu.: 50.00   1st Qu.: 50.00   1st Qu.: 45.00  
##  Median : 65.00   Median : 70.00   Median : 65.00  
##  Mean   : 72.97   Mean   : 72.12   Mean   : 68.75  
##  3rd Qu.: 95.00   3rd Qu.: 90.00   3rd Qu.: 90.00  
##  Max.   :194.00   Max.   :230.00   Max.   :200.00</code></pre>
<p>As you can see the max total stat of any Pokemon is 780, while the min is 175.
That’s quite a big margin. To visualize the distribution of the Pokemon totals we can
use a histogram.</p>
<pre class="r"><code>#plotting data:
ggplot(pD, aes(x=Total)) + geom_histogram(binwidth = 10, color=&quot;black&quot;, fill=&quot;white&quot;) +
  scale_x_continuous(breaks = seq(0, 1150, 50)) +
  geom_vline(xintercept = mean(pD$Total), col=&quot;blue&quot;, linetype = &quot;dashed&quot;, size = 1) +
  geom_density(fill=&quot;red&quot;, alpha=.2, aes(y=10 * ..count..,))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Here we can see the mean of the total stat, which is ~440. We can also see that
the most common total base stats are between 480 and 500.</p>
<p>But what are the best and the worst Pokemon? To find this out we can combine
our quickAnalysis function with dplyr’s filter function.</p>
<pre class="r"><code>(best_pkmn &lt;- pD %&gt;% filter(Total==max(Total)))</code></pre>
<pre><code>## # A tibble: 3 x 10
##     `#` Name       Type     Total    HP Attack Defense `Sp. Atk` `Sp. Def` Speed
##   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;
## 1   150 Mewtwo Me~ Psychic~   780   106    190     100       154       100   130
## 2   150 Mewtwo Me~ Psychic    780   106    150      70       194       120   140
## 3   384 Rayquaza ~ Dragon ~   780   105    180     100       180       100   115</code></pre>
<p>The best Pokemon are the mega evolutions of Mewtwo and Rayquaza with a base stat total of 780.</p>
<pre class="r"><code>(worst_pkmn &lt;- pD %&gt;% filter(Total==min(Total)))</code></pre>
<pre><code>## # A tibble: 1 x 10
##     `#` Name          Type  Total    HP Attack Defense `Sp. Atk` `Sp. Def` Speed
##   &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;
## 1   746 Wishiwashi S~ Water   175    45     20      20        25        25    40</code></pre>
<p>And the worst Pokemon is Wishiwashi’s solo form with a base stat total of 175.</p>
<p>I also wanted to make a boxplot showing the different stats. To do that we had
to reshape our dataframe from a wide-format to a long-format.</p>
<pre class="r"><code>#reshaping data to plot
type_v &lt;- vector()

for (i in 5:10){
  type_v &lt;- c(type_v, rep(pD %&gt;% select(i) %&gt;% names(), 1044))
}</code></pre>
<pre><code>## Note: Using an external vector in selections is ambiguous.
## i Use `all_of(i)` instead of `i` to silence this message.
## i See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.
## This message is displayed once per session.</code></pre>
<pre class="r"><code>value_v &lt;- vector()

for (i in 5:10){
  value_v &lt;- c(value_v, pD %&gt;% select(i) %&gt;% pull())
}


plotDF &lt;- data.frame(type_v, value_v)</code></pre>
<p>When using dplyr slice or select commands be sure to also use pull() to transform
the data into a vector.</p>
<p>Now we are able to create a boxplot.</p>
<pre class="r"><code>ggplot(plotDF, aes(x=value_v, y=type_v, color=type_v)) +
  geom_point() +
  geom_boxplot(alpha=0.8)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>We can see again that the attack stat has the highest median.
It’s also visible that the HP stat has a lot of outliers.</p>
<p>As always you can find the code for the <a href="https://github.com/SvenNekula/webcrawler" target="_blank">crawler</a> and the
<a href="https://github.com/SvenNekula/CrawlerAnalysis" target="_blank">analysis</a> on
my GitHub.
That’s it for this post. Thanks for reading, see you again next time!</p>
<p>-SN</p>
</div>
